Havu – A Gentle AI Companion for Mental Wellbeing

Final project for the Building AI course

Havu is a non-clinical AI-powered wellbeing assistant that supports users through gentle daily check-ins, reflective prompts, and emotional awareness. It helps people pause, reflect, and better understand their mental state in a calm, ethical, and privacy-respecting way.

Mental stress, emotional overload, and feelings of disconnection are increasingly common, especially in modern digital societies. Many people hesitate to seek professional help early, while existing apps often feel intrusive, overwhelming, or overly clinical.

This project aims to address:

Lack of accessible, low-pressure mental wellbeing support

Overuse of complex or addictive mental health apps

Limited emotional self-awareness in everyday life

The gap between doing nothing and seeking professional help

My personal motivation comes from observing how many people struggle silently with their mental wellbeing, especially in Northern European contexts where emotional expression can be minimal. This topic is important because early reflection and awareness can prevent deeper issues later, without replacing professional care.

Havu is designed to be used in short, calm moments during the day — for example in the morning, during a break, or before sleep.

The user can:

Check in with a simple question like “How are you today?”

Respond with a short text or even just an emoji

Read short reflective texts or grounding prompts

Optionally access human professionals through external services

The solution is intended for individuals who want light emotional support without pressure, diagnosis, or constant notifications. The needs of privacy, emotional safety, and cultural sensitivity are central to the design.

![Image of a lake and forest](https://commons.wikimedia.org/w/index.php?search=nordic+summer+forest&title=Special%3AMediaSearch&type=image)

<img src="https://commons.wikimedia.org/w/index.php?search=nordic+summer+forest&title=Special%3AMediaSearch&type=image" width="300">

Havu primarily relies on user-provided, voluntary input, such as short text responses or emoji-based mood signals.

AI techniques potentially used include:

Natural Language Processing (NLP) for understanding text sentiment

Simple machine learning models for pattern recognition over time

Optional deep learning models to personalize responses based on user interaction history (without creating psychological profiles)

Rule-based systems combined with probabilistic reasoning, as introduced in the Building AI course

No external social media data is required. The system is designed to work with minimal data and prioritize data quality, transparency, and user consent.

This project does not:

Diagnose mental health conditions

Replace therapists, psychologists, or medical professionals

Handle crisis situations on its own

Limitations and ethical considerations include:

Avoiding emotional dependency on the AI

Preventing misinterpretation of AI-generated responses

Ensuring strict data privacy and informed consent

Clearly communicating that the tool is supportive, not medical

In the future, Havu could:

Expand to additional European countries with cultural adaptation

Integrate optional professional support networks

Improve personalization while maintaining ethical boundaries

Collaborate with public health or research institutions using anonymized, aggregated data

To move forward, skills needed include UX design, applied AI engineering, ethics-by-design frameworks, and collaboration with mental health professionals.

Inspiration from the University of Helsinki – Building AI course

Concepts influenced by ethical AI, human-centered design, and Nordic wellbeing philosophy

No external datasets or proprietary code are used in this project
