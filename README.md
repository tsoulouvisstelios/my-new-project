# Havu – A Gentle AI Companion for Mental Wellbeing

Final project for the Building AI course

## Summary

Havu is a non-clinical AI-powered wellbeing assistant that supports users through gentle daily check-ins, reflective prompts, and emotional awareness. It helps people pause, reflect, and better understand their mental state in a calm, ethical, and privacy-respecting way.

## Background

Mental stress, emotional overload, and feelings of disconnection are increasingly common, especially in modern digital societies. Many people hesitate to seek professional help early, while existing apps often feel intrusive, overwhelming, or overly clinical.

This project aims to address:
- Lack of accessible, low-pressure mental wellbeing support
- Overuse of complex or addictive mental health apps
- Limited emotional self-awareness in everyday life
- The gap between doing nothing and seeking professional help

My personal motivation comes from observing how many people struggle silently with their mental wellbeing, especially in Northern European contexts where emotional expression can be minimal. This topic is important because early reflection and awareness can prevent deeper issues later, without replacing professional care.

## How is it used?

Havu is designed to be used in short, calm moments during the day — for example in the morning, during a break, or before sleep.

The user can:
- Check in with a simple question like “How are you today?”
- Respond with a short text or even just an emoji
- Read short reflective texts or grounding prompts
- Optionally access human professionals through external services

The solution is intended for individuals who want light emotional support without pressure, diagnosis, or constant notifications. Privacy, emotional safety, and cultural sensitivity are central to the design.

![Nordic calm](havu-mood.jpg)

## Data sources and AI methods

Havu primarily relies on user-provided, voluntary input, such as short text responses or emoji-based mood signals.

AI techniques potentially used include:
- Natural Language Processing (NLP) for understanding text sentiment
- Simple machine learning models for pattern recognition over time
- Optional deep learning models to personalize responses based on interaction history (without psychological profiling)
- Rule-based and probabilistic methods as introduced in the Building AI course

No external social media data is required. The system is designed to work with minimal data and prioritize transparency and user consent.

## Challenges

This project does not:
- Diagnose mental health conditions
- Replace therapists, psychologists, or medical professionals
- Handle crisis situations on its own

Ethical and practical limitations include:
- Avoiding emotional dependency on the AI
- Preventing misinterpretation of AI-generated responses
- Ensuring strict data privacy and informed consent
- Clearly communicating that the tool is supportive, not medical

## What next?

In the future, Havu could:
- Expand to additional European countries with cultural adaptation
- Integrate optional professional support networks
- Improve personalization while maintaining ethical boundaries
- Collaborate with public health or research institutions using anonymized, aggregated data

Further development would require UX design, applied AI engineering, ethics-by-design frameworks, and collaboration with mental health professionals.

## Acknowledgments

- Inspiration from the University of Helsinki – Building AI course
- Influenced by ethical AI principles, human-centered design, and Nordic wellbeing philosophy


